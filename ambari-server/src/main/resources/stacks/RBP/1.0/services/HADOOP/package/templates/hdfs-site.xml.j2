<?xml version="1.0" encoding="UTF-8"?>
<?xml-stylesheet type="text/xsl" href="configuration.xsl"?>
<!--
/**
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
-->

<configuration>

    <property>
       <name>dfs.secondary.http.address</name>
       <value>{{ hdfs_snamenode }}:50090</value>
       <description>SecondaryNameNodeHostname</description>
    </property>

    <property>
        <name>dfs.replication</name>
        <value>{{ dfs_repication }}</value>
        <description>Default block replication.
            The actual number of replications can be specified when the file is created.
            The default is used if replication is not specified in create time.
        </description>
    </property>

    <property>
        <name>dfs.namenode.name.dir</name>
        <value>{{ dfs_namenode_dir }}</value>
        <description>Determines where on the local filesystem the DFS name node should store the name table(fsimage). If this is a comma-delimited list of directories then the name table is replicated in all of the directories, for redundancy.
        </description>
    </property>

    <property>
        <name>dfs.datanode.data.dir</name>
        <value>{{ dfs_datanode_dir }}</value>
        <description>Determines where on the local filesystem an DFS data node should store its blocks. If this is a comma-delimited list of directories, then data will be stored in all named directories, typically on different devices. Directories that do not exist are ignored.
        </description>
    </property>

    <property>
      <name>dfs.nameservices</name>
      <value>{{ dfs_nameservices }}</value>
    </property>

    <property>
      <name>dfs.ha.namenodes.{{ dfs_nameservices }}</name>
      <value>{{ dfs_namenodes }}</value>
    </property>

    {% for host in hdfs_namenodes -%}
    <property>
      <name>dfs.namenode.rpc-address.{{ dfs_nameservices }}.nn{{loop.index}}</name>
      <value>{{host}}:8020</value>
    </property>
    {% endfor %}

    {% for host in hdfs_namenodes -%}
    <property>
      <name>dfs.namenode.http-address.{{ dfs_nameservices }}.nn{{loop.index}}</name>
      <value>{{host}}:50070</value>
    </property>
    {% endfor %}

    <property>
      <name>dfs.namenode.shared.edits.dir</name>
      <value>qjournal://{{":8485;".join(hdfs_namenodes)}}:8485/{{ dfs_nameservices }}</value>
    </property>

    <property>
      <name>dfs.client.failover.proxy.provider.{{ dfs_nameservices }}</name>
      <value>org.apache.hadoop.hdfs.server.namenode.ha.ConfiguredFailoverProxyProvider</value>
    </property>

    <property>
      <name>dfs.ha.fencing.methods</name>
      <value>shell(/bin/true)</value>
    </property>

    <property>
      <name>dfs.journalnode.edits.dir</name>
      <value>{{ dfs_journalnode_dir }}</value>
    </property>

    <property>
      <name>dfs.ha.automatic-failover.enabled</name>
      <value>true</value>
    </property>

</configuration>
