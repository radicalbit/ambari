<?xml version="1.0"?>
<?xml-stylesheet type="text/xsl" href="configuration.xsl"?>
<!--
  ~ Licensed to the Apache Software Foundation (ASF) under one
  ~ or more contributor license agreements.  See the NOTICE file
  ~ distributed with this work for additional information
  ~ regarding copyright ownership.  The ASF licenses this file
  ~ to you under the Apache License, Version 2.0 (the
  ~ "License"); you may not use this file except in compliance
  ~ with the License.  You may obtain a copy of the License at
  ~
  ~     http://www.apache.org/licenses/LICENSE-2.0
  ~
  ~ Unless required by applicable law or agreed to in writing, software
  ~ distributed under the License is distributed on an "AS IS" BASIS,
  ~ WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
  ~ See the License for the specific language governing permissions and
  ~ limitations under the License.
  -->

<configuration>

  <!--Common Options-->

  <property>
    <name>jobmanager.rpc.address</name>
    <value>localhost</value>
    <description>The IP address of the JobManager, which is the master/coordinator of the distributed system</description>
  </property>

  <property>
    <name>jobmanager.rpc.port</name>
    <value>6123</value>
    <description>The port number of the JobManager</description>
  </property>

  <property>
    <name>jobmanager.heap.mb</name>
    <value>512</value>
    <description>JVM heap size (in megabytes) for the JobManager.
      You may have to increase the heap size for the JobManager if you are running very large
      applications (with many operators), or if you are keeping a long history of them.</description>
  </property>

  <property>
    <name>taskmanager.heap.mb</name>
    <value>1024</value>
    <description>JVM heap size (in megabytes) for the TaskManagers, which are the parallel workers of the system.
      In contrast to Hadoop, Flink runs operators (e.g., join, aggregate) and user-defined functions
      (e.g., Map, Reduce, CoGroup) inside the TaskManager (including sorting/hashing/caching),
      so this value should be as large as possible. If the cluster is exclusively running Flink,
      the total amount of available memory per machine minus some memory for the operating system (maybe 1-2 GB)
      is a good value. On YARN setups, this value is automatically configured to the size of the TaskManager’s YARN container,
      minus a certain tolerance value.</description>
  </property>

  <property>
    <name>taskmanager.numberOfTaskSlots</name>
    <value>1</value>
    <description>The number of parallel operator or user function instances that a single TaskManager can run.
      If this value is larger than 1, a single TaskManager takes multiple instances of a function or operator.
      That way, the TaskManager can utilize multiple CPU cores, but at the same time, the available memory is
      divided between the different operator or function instances. This value is typically proportional to
      the number of physical CPU cores that the TaskManager’s machine has (e.g., equal to the number of cores,
      or half the number of cores).</description>
  </property>

  <property>
    <name>parallelism.default</name>
    <value>1</value>
    <description>The default parallelism to use for programs that have no parallelism specified.
      For setups that have no concurrent jobs running, setting this value to NumTaskManagers * NumSlotsPerTaskManager
      will cause the system to use all available execution resources for the program’s execution. Note: The default
      parallelism can be overwriten for an entire job by calling setParallelism(int parallelism) on the
      ExecutionEnvironment or by passing -p [parallelism] to the Flink Command-line frontend. It can be overwritten
      for single transformations by calling setParallelism(int parallelism) on an operator. </description>
  </property>

  <!--Advanced Options-->

  <property>
    <name>taskmanager.memory.size</name>
    <value>-1</value>
    <description>The amount of memory (in megabytes) that the task manager reserves on the JVM’s heap space for
      sorting, hash tables, and caching of intermediate results. If unspecified (-1), the memory manager will
      take a fixed ratio of the heap memory available to the JVM,
      as specified by taskmanager.memory.fraction.</description>
  </property>

  <property>
    <name>taskmanager.memory.fraction</name>
    <value>0.7</value>
    <description>The relative amount of memory that the task manager reserves for sorting,
      hash tables, and caching of intermediate results. For example,
      a value of 0.8 means that TaskManagers reserve 80% of the JVM’s heap space
      for internal data buffers, leaving 20% of the JVM’s heap space free for
      objects created by user-defined functions. This parameter is only evaluated,
      if taskmanager.memory.size is not set.</description>
  </property>

  <property>
    <name>taskmanager.memory.segment-size</name>
    <value>32768</value>
    <description>The size of memory buffers used by the memory manager and the network stack in bytes</description>
  </property>

  <property>
    <name>taskmanager.memory.preallocate</name>
    <value>false</value>
    <description>Can be either of true or false. Specifies whether task managers should
      allocate all managed memory when starting up.</description>
  </property>

  <property>
    <name>taskmanager.tmp.dirs</name>
    <value>/tmp</value>
    <description>The directory for temporary files, or a list of directories separated by the systems
      directory delimiter (for example ‘:’ (colon) on Linux/Unix). If multiple directories are specified,
      then the temporary files will be distributed across the directories in a round-robin fashion.
      The I/O manager component will spawn one reading and one writing thread per directory.
      A directory may be listed multiple times to have the I/O manager use multiple threads
      for it (for example if it is physically stored on a very fast disc or RAID)</description>
  </property>

  <property>
    <name>jobmanager.web.port</name>
    <value>8081</value>
    <description>Port of the JobManager’s web interface</description>
  </property>

  <property>
    <name>fs.output.always-create-directory</name>
    <value>false</value>
    <description>File writers running with a parallelism larger than one create a directory
      for the output file path and put the different result files (one per parallel writer task)
      into that directory. If this option is set to true, writers with a parallelism of
      1 will also create a directory and place a single result file into it. If the option
      is set to false, the writer will directly create the file directly at the output path,
      without creating a containing directory.</description>
  </property>

  <property>
    <name>taskmanager.network.numberOfBuffers</name>
    <value>2048</value>
    <description>The number of buffers available to the network stack.
      This number determines how many streaming data exchange channels a TaskManager
      can have at the same time and how well buffered the channels are. If a job is
      rejected or you get a warning that the system has not enough buffers available,
      increase this value</description>
  </property>

  <property>
    <name>state.backend</name>
    <value>filesystem</value>
    <description>The backend that will be used to store operator state checkpoints if
      checkpointing is enabled. Supported backends: filesystem, jobmanager</description>
  </property>

  <property>
    <name>blob.storage.directory</name>
    <value></value>
    <description>Directory for storing blobs (such as user jar’s) on the TaskManagers.</description>
    <value-attributes>
      <empty-value-valid>true</empty-value-valid>
    </value-attributes>
  </property>

  <property>
    <name>blob.server.port</name>
    <value>0</value>
    <description>Port definition for the blob server (serving user jar’s) on the Taskmanagers.
      By default the port is set to 0, which means that the operating system is
      picking an ephemeral port. Flink also accepts a list of ports (“50100,50101”),
      ranges (“50100-50200”) or a combination of both. It is recommended to set a
      range of ports to avoid collisions when multiple JobManagers are running on
      the same machine.</description>
  </property>

  <!--JobManager Web Frontend-->

  <property>
    <name>jobmanager.web.port</name>
    <value>8081</value>
    <description>Port of the JobManager’s web interface that displays status of running
      jobs and execution time breakdowns of finished jobs.
      Setting this value to -1 disables the web frontend.</description>
  </property>

  <property>
    <name>jobmanager.web.history</name>
    <value>5</value>
    <description>The number of latest jobs that the JobManager’s web
      front-end in its history</description>
  </property>

  <property>
    <name>jobmanager.web.checkpoints.disable</name>
    <value>false</value>
    <description>Disables checkpoint statistics</description>
  </property>

  <property>
    <name>jobmanager.web.checkpoints.history</name>
    <value>10</value>
    <description>Number of checkpoint statistics to remember</description>
  </property>

  <!--YARN-->

  <property>
    <name>yarn.application-master.port</name>
    <value>0</value>
    <description>With this configuration option, users can specify a port, a range of ports
      or a list of ports for the Application Master (and JobManager) RPC port.
      By default we recommend using the default value (0) to let the operating system
      choose an appropriate port. In particular when multiple AMs are running on the same
      physical host, fixed port assignments prevent the AM from starting.</description>
  </property>

  <!--High Availability Mode-->

  <property>
    <name>recovery.mode</name>
    <value>zookeeper</value>
    <description>Defines the recovery mode used for the cluster execution. Currently,
      Flink supports the ‘standalone’ mode where only a single JobManager runs and
      no JobManager state is checkpointed. The high availability mode ‘zookeeper’
      supports the execution of multiple JobManagers and JobManager state checkpointing.
      Among the group of JobManagers, ZooKeeper elects one of them as the leader which
      is responsible for the cluster execution. In case of a JobManager failure,
      a standby JobManager will be elected as the new leader and is given the
      last checkpointed JobManager state.</description>
  </property>

  <!-- params for service -->

  <!--<property>-->
    <!--<name>flink_numcontainers</name>-->
    <!--<value>1</value>-->
    <!--<description>Number of YARN container to allocate (=Number of Task Managers)</description>-->
  <!--</property> -->

  <!--<property>-->
    <!--<name>flink_appname</name>-->
    <!--<value>flink-yarn-shell</value>-->
    <!--<description>Flink application name</description>-->
  <!--</property> -->

  <!--<property>-->
    <!--<name>flink_queue</name>-->
    <!--<value>default</value>-->
    <!--<description>YARN queue to schedule Flink job on</description>-->
  <!--</property> -->

  <!--<property>-->
    <!--<name>flink_streaming</name>-->
    <!--<value>false</value>-->
    <!--<description>If true, Flink will be started in streaming mode: to be used when only streaming jobs will be executed on Flink</description>-->
  <!--</property> -->
  
  <!--<property>-->
    <!--<name>flink_jobmanager_memory</name>-->
    <!--<value>768</value>-->
    <!--<description>Memory for JobManager Container [in MB]. Must be at least 768</description>-->
  <!--</property> -->
      <!---->
  <!--<property>-->
    <!--<name>flink_container_memory</name>-->
    <!--<value>1024</value>-->
    <!--<description>Memory per TaskManager Container [in MB]</description>-->
  <!--</property>-->
    
</configuration>  